{"name":"Conqueue","body":"Conqueue\r\n======\r\nConqueue is a queue manager library built on the top of redis. You can create jobs in queues, and process later with worker\r\nscripts asynchronously.\r\n\r\nInstallation\r\n-------------\r\n\r\n```\r\ngit clone git://github.com/emre/conqueue.git\r\nsudo python setup.py install\r\n```\r\nIn order to use conqueue, you need to install redis-py library (sudo pip install redis), and a working redis-server instance.\r\n\r\nConqueue works with Configuration objects. There are some options you can choose for conqueue's workflow.\r\n\r\nA simple worker script that listens 'feeds' queue.\r\n\r\n``` python\r\nfrom conqueue.conqueue import Conqueue\r\nfrom conqueue.lib.config import BaseConfig\r\n\r\nclass Configuration(BaseConfig):\r\n   REDIS_SERVER_INFO = {\r\n      'host'     : 'localhost',\r\n      'port'     : 6379,\r\n      'db'       : 0,\r\n   }\r\n\r\n   USE_MULTI_PROCESSING = True\r\n   POOLSIZE_PER_WORKER  = 5\r\n\r\ndef parse_feed(data):\r\n    import time\r\n    # make something with the feed\r\n    time.sleep(2)\r\n    print data\r\n\r\n# listens two queues: ['feeds', 'messages']\r\nworker = Conqueue(Configuration).worker()\r\nworker.register_task('feeds', parse_feed)\r\n\r\nworker.listen_tasks()\r\n\r\n```\r\n\r\nClient script that puts jobs to the worker:\r\n\r\n``` python\r\nfrom conqueue.conqueue import Conqueue\r\n\r\nclient  = Conqueue(Configuration).client()\r\nclient.add_task('messages', 'how you doing?')\r\n```\r\n\r\nConfiguration Options\r\n-------------\r\n### USE_MULTI_PROCESSING\r\n_default: True_\r\n\r\nIf set True, conqueue forks worker function based on cpu count by default.\r\n\r\n### POOLSIZE_PER_WORKER\r\n_default: None_\r\n\r\nIf you don't set this explicitly, conqueue forks workers based on CPU count. (which is recommended.)\r\n\r\n### PREFIX = 'conqueue'\r\n_default: conqueue_\r\n\r\nPrefix for the redis keys.\r\n\r\n### RETRY_BEHAVIOUR\r\n_default: (True, 100)_\r\n\r\nif worker functions raises any exception, conqueue catches it, and requeue if you want. First argument is for enabling/disabling.\r\nsecond argument is for retry count.\r\n\r\nTask Priority\r\n-------------\r\nThere is no support for this. But you can do it manually by creating more instances for your workers. If you use register_task more than one\r\nin one worker, first registered queue will have high priority.\r\n\r\nBasic Admin Script\r\n-------------\r\nthere is a simple and stupid script for queue monitoring in the /tools directory. A frontend with more meaningful information\r\nwill be added in the future.\r\n\r\n```\r\nemre@amy:~/github_projects/conqueue/tools$ python conqueue-admin.py\r\nconqueue:feeds 15\r\nconqueue:feeds:failed 1\r\nconqueue:messages 5\r\n```\r\n\r\nTodo\r\n------------\r\n* Management/Monitoring Frontend\r\n* _Optional_ gevent based pool instead of multiprocessing library.\r\n* Redis sharding in the back. (with consistent hashing: <http://emreyilmaz.me/implementing-consistent-hashing-into-your-redis>)\r\n\r\nNotes\r\n------------\r\nRemember that, conqueue is not tested well. It is a weekend hackathon project, and still in early development.","tagline":"conqueue is a queue manager library built on the top of redis.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}